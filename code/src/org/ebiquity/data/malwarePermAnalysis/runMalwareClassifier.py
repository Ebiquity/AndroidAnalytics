"""
Created on July 12,2017
@author: Prajit Kumar Das

Usage: python runMalwareClassifier.py\n
"""
import os
import json
import sys
import time
import datetime
from random import sample
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import classification_report
from sklearn.multiclass import OneVsRestClassifier
from sklearn.dummy import DummyClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix
from sklearn.feature_selection import chi2
from scipy import stats
import numpy as np
import pandas as pd
import databaseHandler as db
import logging
logging.basicConfig(filename="classification.log",level=logging.DEBUG)

benign=0
malware=1
testRatio=0.25

names = ["Dummy",
		 "Linear SVM",
		 "Nearest Neighbors",
		 "Decision Tree",
		 "Random Forest",
		 "RBF SVM",
		 "Neural Net",
		 "AdaBoost",
		 "Naive Bayes",
		 "Logistic Regression"]		 
classifiers = [DummyClassifier(strategy="most_frequent"),
				SVC(kernel="linear", C=1),
				KNeighborsClassifier(3),
				DecisionTreeClassifier(max_depth=5),
				RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
				SVC(kernel="poly", C=1),
				MLPClassifier(alpha=1),
				AdaBoostClassifier(),
				GaussianNB(),
				LogisticRegression(solver="sag")]

def doClassify(X,y):
	resultDict={}
	X_train, X_test, y_train, y_test = \
		train_test_split(X, y, stratify=y, test_size=testRatio, random_state=42)
	X_train = StandardScaler().fit_transform(X_train)
	X_test = StandardScaler().fit_transform(X_test)
	# iterate over classifiers
	for name, clf in zip(names, classifiers):
		print "Running cliasifer:", name
		clf.fit(X_train, y_train)
		y_pred=clf.predict(X_test)
		y_pred_=clf.predict(X_train)
		prf1sDict={}
		# chi,pval = chi2(X_train, y_train)
		# prf1sDict["chi2"] = chi
		# prf1sDict["pval"] = pval
		precision = 0
		recall = 0
		fscore = 0
		support = 0
		try:
			precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average="weighted")
			logging.debug(str(precision)+","+str(recall)+","+str(fscore)+","+str(support)+","+name)
			score=clf.score(X_test, y_test)
			prf1sDict["testReport"] = classification_report(y_test, y_pred)
			tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
			prf1sDict["testTN"] = tn
			prf1sDict["testFP"] = fp
			prf1sDict["testFN"] = fn
			prf1sDict["testTP"] = tp
			prf1sDict["testScore"] = score
			prf1sDict["testPrecision"] = precision
			prf1sDict["testRecall"] = recall
			prf1sDict["testFscore"] = fscore
			precision_, recall_, fscore_, support_ = precision_recall_fscore_support(y_train, y_pred_, average="weighted")
			score_=clf.score(X_train, y_train)
			prf1sDict["trainReport"] = classification_report(y_train, y_pred_)
			tn, fp, fn, tp = confusion_matrix(y_train, y_pred_).ravel()
			prf1sDict["trainTN"] = tn
			prf1sDict["trainFP"] = fp
			prf1sDict["trainFN"] = fn
			prf1sDict["trainTP"] = tp
			prf1sDict["trainScore"] = score_
			prf1sDict["trainPrecision"] = precision_
			prf1sDict["trainRecall"] = recall_
			prf1sDict["trainFscore"] = fscore_
			print prf1sDict
			resultDict[name] = prf1sDict
		except ValueError:
			print "Error for claissifier:", name
			print "Unexpected error in test:", sys.exc_info()
			continue
	return resultDict

def getBenignAppPermissionsFromDataJson(appDict):
	bigDict = {}
	# featuresList = []
	permissionsList = []
	appList = sample(appDict.keys(), 10000)
	for pkgName in appList:
		permissions = appDict[pkgName]

		extractedDict = {}
		extractedDict["benignMal"] = benign
		extractedDict["platformVer"] = ""
		extractedDict["pkgName"] = pkgName
		extractedDict["features"] = []
		extractedDict["permissions"] = permissions

		for permission in permissions:
			permissionsList.append(permission)

		bigDict[pkgName] = extractedDict

	# return list(set(featuresList)), list(set(permissionsList)), bigDict
	return list(set(permissionsList)), bigDict

def getMalwareAppPermissionsFromDataJson(appDict):
	bigDict = {}
	# featuresList = []
	permissionsList = []
	for app in appDict:
		extractedDict = {}
		pkgName = appDict[app]["pkgName"]

		if appDict[app]["benignMal"] == "benign":
			extractedDict["benignMal"] = benign
		else:
			extractedDict["benignMal"] = malware

		extractedDict["platformVer"] = appDict[app]["platformVer"]
		extractedDict["pkgName"] = pkgName
		extractedDict["features"] = appDict[app]["features"]
		extractedDict["permissions"] = appDict[app]["permissions"]

		# for feature in appDict[app]["features"]:
		# 	featuresList.append(feature)

		for permission in appDict[app]["permissions"]:
			permissionsList.append(permission)

		bigDict[pkgName] = extractedDict

	# return list(set(featuresList)), list(set(permissionsList)), bigDict
	return list(set(permissionsList)), bigDict

def runClassification():
	allAppsDict = {}
	# featuresList = []
	permissionsList = []

	malwareDict = json.loads(open("malware.json","r").read())
	benignADict = json.loads(open("data.json","r").read())

	# print len(malwareDict.keys())
	# print len(benignADict.keys())

	# featureList1, permissionsList1, extractedDict1 = getMalwareAppPermissionsFromDataJson(malwareDict)
	# featuresList2, permissionsList2, extractedDict2 = getBenignAppPermissionsFromDataJson(benignADict)

	permissionsList1, extractedDict1 = getMalwareAppPermissionsFromDataJson(malwareDict)
	permissionsList2, extractedDict2 = getBenignAppPermissionsFromDataJson(benignADict)

	# featuresList = list(set(featureList1 + featuresList2))

	permissionsList = list(set(permissionsList1 + permissionsList2))

	allAppsDict = extractedDict1
	allAppsDict.update(extractedDict2)

	# print len(permissionsList)
	# print len(allAppsDict)

	X = []
	y = []

	for app in allAppsDict:
		# if allAppsDict[app]["benignMal"] == benign:
		# 	print "extracting features for benign app:", app
		# else:
		# 	print "extracting features for malware app:", app
		
		classificationFeatures = []

		# for feature in featuresList:
		# 	if feature in allAppsDict[app]["features"]:
		# 		classificationFeatures.append(1)
		# 	else:
		# 		classificationFeatures.append(0)

		for permission in permissionsList:
			if permission in allAppsDict[app]["permissions"]:
				classificationFeatures.append(1)
			else:
				classificationFeatures.append(0)

		X.append(classificationFeatures)
		y.append(allAppsDict[app]["benignMal"])

	print len(X)
	print len(y)

	return X,y
	
def pairedSampleChiSquaredTest(X,y):
	print "Paired Sample T-Test"

	benign = []
	malware = []
	index = 0
	for benignMal in y:
		if benignMal == benign:
			benign.append(X[index])
		else:
			malware.append(X[index])
		index += 1
	
	pValues = 0.0
	lengthToUse = min(len(benign), len(malware))
	# print type(lengthToUse)
	# print lengthToUse
	# for loopCount in range(100000):
	index = 10#np.random.choice(lengthToUse)
	a = benign[index]
	b = malware[index]
	if not np.array_equal(a, b):
		stat, pval = stats.levene(a,b)
		pValues += pval
		print "Index chosen:", index
		print "The t-statistic is", stat, "and the p-value is", pval

	# print "Average p-value:", pValues/100000.0

def featureImportance(X,y):
	resultDict={}
	X_train, X_test, y_train, y_test = \
		train_test_split(X, y, stratify=y, test_size=testRatio, random_state=42)
	X_train = StandardScaler().fit_transform(X_train)
	X_test = StandardScaler().fit_transform(X_test)
	mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=100, alpha=1e-4, solver='sgd', verbose=100, tol=1e-4, random_state=1, learning_rate_init=.1)
	mlp.fit(X_train, y_train)
	print("Training set score: %f" % mlp.score(X_train, y_train))
	print("Test set score: %f" % mlp.score(X_test, y_test))

	fig, axes = plt.subplots(4, 4)
	# use global min / max to ensure all weights are shown on the same scale
	vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()
	for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):
		ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin, vmax=.5 * vmax)
		ax.set_xticks(())
		ax.set_yticks(())

	plt.show()

def main(argv):
	startTime = time.time()
	X,y = runClassification()
	# pairedSampleChiSquaredTest(X,y)
	featureImportance(X,y)
	# result = doClassify(X,y)
	# open("results.json","w").write(json.dumps(result, indent=4))
	executionTime = str((time.time()-startTime)/60)
	print "Execution time was: "+executionTime+" minutes"

if __name__ == "__main__":
	main(sys.argv)