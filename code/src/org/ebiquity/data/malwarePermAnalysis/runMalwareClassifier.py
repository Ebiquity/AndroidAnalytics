"""
Created on July 12,2017
@author: Prajit Kumar Das

Usage: python runMalwareClassifier.py\n
"""
import os
import json
import sys
import time
import datetime
from random import sample
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import classification_report
from sklearn.multiclass import OneVsRestClassifier
from sklearn.dummy import DummyClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix
from sklearn.feature_selection import chi2
import matplotlib.pyplot as plt
from scipy import stats
import numpy as np
import pandas as pd
import databaseHandler as db
import logging
logging.basicConfig(filename="classification.log",level=logging.DEBUG)

benign=0
malware=1
testRatio=0.25

names = ["Dummy",
		 "Linear SVM",
		 "Nearest Neighbors",
		 "Decision Tree",
		 "Random Forest",
		 "RBF SVM",
		 "Neural Net",
		 "AdaBoost",
		 "Naive Bayes",
		 "Logistic Regression"]		 
classifiers = [DummyClassifier(strategy="most_frequent"),
				SVC(kernel="linear", C=1),
				KNeighborsClassifier(3),
				DecisionTreeClassifier(max_depth=5),
				RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
				SVC(kernel="poly", C=1),
				MLPClassifier(alpha=1),
				AdaBoostClassifier(),
				GaussianNB(),
				LogisticRegression(solver="sag")]

def doClassify(X,y):
	resultDict={}
	X_train, X_test, y_train, y_test = \
		train_test_split(X, y, stratify=y, test_size=testRatio, random_state=42)
	X_train = StandardScaler().fit_transform(X_train)
	X_test = StandardScaler().fit_transform(X_test)
	# iterate over classifiers
	for name, clf in zip(names, classifiers):
		print "Running cliasifer:", name
		clf.fit(X_train, y_train)
		y_pred=clf.predict(X_test)
		y_pred_=clf.predict(X_train)
		prf1sDict={}
		# chi,pval = chi2(X_train, y_train)
		# print "chi2", chi
		# print "pval", pval
		precision = 0
		recall = 0
		fscore = 0
		support = 0
		try:
			precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average="weighted")
			logging.debug(str(precision)+","+str(recall)+","+str(fscore)+","+str(support)+","+name)
			score=clf.score(X_test, y_test)
			prf1sDict["testReport"] = classification_report(y_test, y_pred)
			tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
			prf1sDict["testTN"] = tn
			prf1sDict["testFP"] = fp
			prf1sDict["testFN"] = fn
			prf1sDict["testTP"] = tp
			prf1sDict["testScore"] = score
			prf1sDict["testPrecision"] = precision
			prf1sDict["testRecall"] = recall
			prf1sDict["testFscore"] = fscore
			precision_, recall_, fscore_, support_ = precision_recall_fscore_support(y_train, y_pred_, average="weighted")
			score_=clf.score(X_train, y_train)
			prf1sDict["trainReport"] = classification_report(y_train, y_pred_)
			tn, fp, fn, tp = confusion_matrix(y_train, y_pred_).ravel()
			prf1sDict["trainTN"] = tn
			prf1sDict["trainFP"] = fp
			prf1sDict["trainFN"] = fn
			prf1sDict["trainTP"] = tp
			prf1sDict["trainScore"] = score_
			prf1sDict["trainPrecision"] = precision_
			prf1sDict["trainRecall"] = recall_
			prf1sDict["trainFscore"] = fscore_
			resultDict[name] = prf1sDict
		except ValueError:
			print "Error for claissifier:", name
			print "Unexpected error in test:", sys.exc_info()
			continue
	return resultDict

def getBenignAppPermissionsFromDataJson(appDict):
	bigDict = {}
	# featuresList = []
	permissionsList = []
	appList = sample(appDict.keys(), 10000)
	for pkgName in appList:
		permissions = appDict[pkgName]

		extractedDict = {}
		extractedDict["benignMal"] = benign
		extractedDict["platformVer"] = ""
		extractedDict["pkgName"] = pkgName
		extractedDict["features"] = []
		extractedDict["permissions"] = permissions

		for permission in permissions:
			permissionsList.append(permission)

		bigDict[pkgName] = extractedDict

	# return list(set(featuresList)), list(set(permissionsList)), bigDict
	return list(set(permissionsList)), bigDict

def getMalwareAppPermissionsFromDataJson(appDict):
	bigDict = {}
	# featuresList = []
	permissionsList = []
	for app in appDict:
		extractedDict = {}
		pkgName = appDict[app]["pkgName"]

		if appDict[app]["benignMal"] == "benign":
			extractedDict["benignMal"] = benign
		else:
			extractedDict["benignMal"] = malware

		extractedDict["platformVer"] = appDict[app]["platformVer"]
		extractedDict["pkgName"] = pkgName
		extractedDict["features"] = appDict[app]["features"]
		extractedDict["permissions"] = appDict[app]["permissions"]

		# for feature in appDict[app]["features"]:
		# 	featuresList.append(feature)

		for permission in appDict[app]["permissions"]:
			permissionsList.append(permission)

		bigDict[pkgName] = extractedDict

	# return list(set(featuresList)), list(set(permissionsList)), bigDict
	return list(set(permissionsList)), bigDict

def runClassification():
	allAppsDict = {}
	# featuresList = []
	permissionsList = []

	malwareDict = json.loads(open("malware.json","r").read())
	benignADict = json.loads(open("data.json","r").read())

	# print len(malwareDict.keys())
	# print len(benignADict.keys())

	# featureList1, permissionsList1, extractedDict1 = getMalwareAppPermissionsFromDataJson(malwareDict)
	# featuresList2, permissionsList2, extractedDict2 = getBenignAppPermissionsFromDataJson(benignADict)

	permissionsList1, extractedDict1 = getMalwareAppPermissionsFromDataJson(malwareDict)
	permissionsList2, extractedDict2 = getBenignAppPermissionsFromDataJson(benignADict)

	# featuresList = list(set(featureList1 + featuresList2))

	permissionsList = list(set(permissionsList1 + permissionsList2))

	allAppsDict = extractedDict1
	allAppsDict.update(extractedDict2)

	# print len(permissionsList)
	# print len(allAppsDict)

	X = []
	y = []

	malwarePermDict = {}
	benignAppPermDict = {}

	for app in allAppsDict:
		classificationFeatures = []

		# for feature in featuresList:
		# 	if feature in allAppsDict[app]["features"]:
		# 		classificationFeatures.append(1)
		# 	else:
		# 		classificationFeatures.append(0)
		for permission in permissionsList:
			if permission in allAppsDict[app]["permissions"]:
				classificationFeatures.append(1)
			else:
				classificationFeatures.append(0)
			if allAppsDict[app]["benignMal"] == benign:
				if permission in benignAppPermDict:
					benignAppPermDict[permission] += 1
				else:
					benignAppPermDict[permission] = 1
			else:
				if permission in malwarePermDict:
					malwarePermDict[permission] += 1
				else:
					malwarePermDict[permission] = 1

		X.append(classificationFeatures)
		y.append(allAppsDict[app]["benignMal"])

	# print len(X)
	# print len(y)

	return X,y,permissionsList,malwarePermDict,benignAppPermDict
	
def pairedSampleTTest(X,y):
	print "Paired Sample T-Test"

	benign = []
	malware = []
	index = 0
	for benignMal in y:
		if benignMal == benign:
			benign.append(X[index])
		else:
			malware.append(X[index])
		index += 1
	
	pValues = 0.0
	lengthToUse = min(len(benign), len(malware))
	# print type(lengthToUse)
	# print lengthToUse
	# for loopCount in range(100000):
	index = 10#np.random.choice(lengthToUse)
	a = benign[index]
	b = malware[index]
	if not np.array_equal(a, b):
		stat, pval = stats.levene(a,b)
		pValues += pval
		print "Index chosen:", index
		print "The t-statistic is", stat, "and the p-value is", pval

	# print "Average p-value:", pValues/100000.0

def MLP(X,y):
	precision = 0
	recall = 0
	fscore = 0
	support = 0

	X_train, X_test, y_train, y_test = \
		train_test_split(X, y, stratify=y, test_size=testRatio, random_state=42)
	X_train = StandardScaler().fit_transform(X_train)
	X_test = StandardScaler().fit_transform(X_test)

	mlp = MLPClassifier(hidden_layer_sizes=(100,100), max_iter=400, alpha=1e-4, solver='sgd', verbose=400, tol=1e-4, random_state=1, learning_rate_init=1e-1)
	# mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=100, alpha=1e-4, solver='sgd', verbose=100, tol=1e-4, random_state=1, learning_rate_init=1e-1)
	mlp.fit(X_train, y_train)

	y_pred = mlp.predict(X_test)
	y_pred_ = mlp.predict(X_train)

	precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average="weighted")
	score = mlp.score(X_test, y_test)
	print "classification_report_test\n", classification_report(y_test, y_pred)
	tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

	precision_, recall_, fscore_, support_ = precision_recall_fscore_support(y_train, y_pred_, average="weighted")
	score_=mlp.score(X_train, y_train)
	print "classification_report_train\n", classification_report(y_train, y_pred_)
	tn, fp, fn, tp = confusion_matrix(y_train, y_pred_).ravel()

	print "testTN", tn
	print "testFP", fp
	print "testFN", fn
	print "testTP", tp
	print "testPrecision", precision
	print "testRecall", recall
	print "testFscore", fscore
	print "Training set score:", score
	print "Test set score:", score_
	print "trainTN", tn
	print "trainFP", fp
	print "trainFN", fn
	print "trainTP", tp
	print "trainPrecision", precision_
	print "trainRecall", recall_
	print "trainFscore", fscore_

	# # print len(mlp.coefs_[0])
	# print mlp.coefs_[0].shape
	# # print mlp.coefs_.shape
	# # arr = np.array(mlp.coefs_)
	# # print arr.shape

	# fig, ax = plt.subplots(1, 1, figsize=(15,6))
	# ax.imshow(np.transpose(mlp.coefs_[0]), cmap=plt.get_cmap("gray"), aspect="auto")
	# # use global min / max to ensure all weights are shown on the same scale
	# vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()
	# # use global min / max to ensure all weights are shown on the same scale
	# plt.matshow(mlp.coefs_[0].reshape(len(mlp.coefs_[0]), 50), cmap=plt.cm.gray, vmin=.5 * vmin, vmax=.5 * vmax)
	# # plt.set_xticks(())
	# # plt.set_yticks(())

	# plt.show()

def featureImportance(X,y,permissionsList):
	precision = 0
	recall = 0
	fscore = 0
	support = 0

	X_train, X_test, y_train, y_test = \
		train_test_split(X, y, stratify=y, test_size=testRatio, random_state=42)
	X_train = StandardScaler().fit_transform(X_train)
	X_test = StandardScaler().fit_transform(X_test)

	# Build a forest and compute the feature importances
	forest = ExtraTreesClassifier(n_estimators=1000,random_state=0)

	forest.fit(X_train, y_train)

	y_pred = forest.predict(X_test)
	y_pred_ = forest.predict(X_train)

	precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average="weighted")
	score = forest.score(X_test, y_test)
	print "classification_report_test\n", classification_report(y_test, y_pred)
	tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

	precision_, recall_, fscore_, support_ = precision_recall_fscore_support(y_train, y_pred_, average="weighted")
	score_=forest.score(X_train, y_train)
	print "classification_report_train\n", classification_report(y_train, y_pred_)
	tn, fp, fn, tp = confusion_matrix(y_train, y_pred_).ravel()

	print "testTN", tn
	print "testFP", fp
	print "testFN", fn
	print "testTP", tp
	print "testPrecision", precision
	print "testRecall", recall
	print "testFscore", fscore
	print "Training set score:", score
	print "Test set score:", score_
	print "trainTN", tn
	print "trainFP", fp
	print "trainFN", fn
	print "trainTP", tp
	print "trainPrecision", precision_
	print "trainRecall", recall_
	print "trainFscore", fscore_

	importances = forest.feature_importances_
	std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)
	indices = np.argsort(importances)[::-1]

	featImpDict = {}
	# Print the feature ranking
	print("Feature ranking:")
	nparray = np.array(X_train)
	for f in range(nparray.shape[1]):
		featImpDict[permissionsList[indices[f]]] = importances[indices[f]]
		if f < 100:
			print("%d. permission %s. feature %d (%f)" % (f + 1, permissionsList[indices[f]], indices[f], importances[indices[f]]))

	# Plot the feature importances of the forest
	plt.figure()
	plt.title("Feature importances")
	plt.bar(range(nparray.shape[1]), importances[indices],
	color="r", yerr=std[indices], align="center")
	plt.xticks(range(nparray.shape[1]), indices)
	plt.xlim([-1, nparray.shape[1]])
	plt.show()

def main(argv):
	startTime = time.time()
	X,y,permissionsList,malwarePermDict,benignAppPermDict = runClassification()
	# pairedSampleTTest(X,y)
	# MLP(X,y)
	resultFeatImp = featureImportance(X,y,permissionsList)
	open("resultFeatImp.json","w").write(json.dumps(resultFeatImp, indent=4))
	# result = doClassify(X,y)
	# open("results.json","w").write(json.dumps(result, indent=4))
	executionTime = str((time.time()-startTime)/60)
	print "Execution time was: "+executionTime+" minutes"

if __name__ == "__main__":
	main(sys.argv)